{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip-gram using Navie-Softmax- CS224n\n",
    "import the neccesarry libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "random.seed(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the version of torch and nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n",
      "3.3\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use suitable device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "gpus = [0]\n",
    "#torch.cuda.set_device(gpus[0])\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function \"getBatch\" accourding to batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBatch(batch_size, train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex: eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "    \n",
    "    if eindex >= len(train_data):\n",
    "        batch = train_data[sindex:]\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare sequences and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return Variable(LongTensor(idxs))\n",
    "\n",
    "def prepare_word(word, word2index):\n",
    "    return Variable(LongTensor([word2index[word]]) if word2index.get(word) is not None else LongTensor([word2index[\"<UNK>\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download gutenberg text files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/bharat/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the corpus .txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download punkt package used for tokens creations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bharat/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one .txt file and print list of corpus upto 100 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = list(nltk.corpus.gutenberg.sents('melville-moby_dick.txt'))[:100] # sampling sentences for test\n",
    "corpus = [[word.lower() for word in sent] for sent in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[', 'moby', 'dick', 'by', 'herman', 'melville', '1851', ']'], ['etymology', '.'], ['(', 'supplied', 'by', 'a', 'late', 'consumptive', 'usher', 'to', 'a', 'grammar', 'school', ')'], ['the', 'pale', 'usher', '--', 'threadbare', 'in', 'coat', ',', 'heart', ',', 'body', ',', 'and', 'brain', ';', 'i', 'see', 'him', 'now', '.'], ['he', 'was', 'ever', 'dusting', 'his', 'old', 'lexicons', 'and', 'grammars', ',', 'with', 'a', 'queer', 'handkerchief', ',', 'mockingly', 'embellished', 'with', 'all', 'the', 'gay', 'flags', 'of', 'all', 'the', 'known', 'nations', 'of', 'the', 'world', '.'], ['he', 'loved', 'to', 'dust', 'his', 'old', 'grammars', ';', 'it', 'somehow', 'mildly', 'reminded', 'him', 'of', 'his', 'mortality', '.'], ['\"', 'while', 'you', 'take', 'in', 'hand', 'to', 'school', 'others', ',', 'and', 'to', 'teach', 'them', 'by', 'what', 'name', 'a', 'whale', '-', 'fish', 'is', 'to', 'be', 'called', 'in', 'our', 'tongue', 'leaving', 'out', ',', 'through', 'ignorance', ',', 'the', 'letter', 'h', ',', 'which', 'almost', 'alone', 'maketh', 'the', 'signification', 'of', 'the', 'word', ',', 'you', 'deliver', 'that', 'which', 'is', 'not', 'true', '.\"'], ['--', 'hackluyt'], ['\"', 'whale', '.'], ['...', 'sw', '.', 'and', 'dan', '.'], ['hval', '.'], ['this', 'animal', 'is', 'named', 'from', 'roundness', 'or', 'rolling', ';', 'for', 'in', 'dan', '.'], ['hvalt', 'is', 'arched', 'or', 'vaulted', '.\"'], ['--', 'webster', \"'\", 's', 'dictionary'], ['\"', 'whale', '.'], ['...'], ['it', 'is', 'more', 'immediately', 'from', 'the', 'dut', '.'], ['and', 'ger', '.'], ['wallen', ';', 'a', '.', 's', '.', 'walw', '-', 'ian', ',', 'to', 'roll', ',', 'to', 'wallow', '.\"'], ['--', 'richardson', \"'\", 's', 'dictionary'], ['ketos', ',', 'greek', '.'], ['cetus', ',', 'latin', '.'], ['whoel', ',', 'anglo', '-', 'saxon', '.'], ['hvalt', ',', 'danish', '.'], ['wal', ',', 'dutch', '.'], ['hwal', ',', 'swedish', '.'], ['whale', ',', 'icelandic', '.'], ['whale', ',', 'english', '.'], ['baleine', ',', 'french', '.'], ['ballena', ',', 'spanish', '.'], ['pekee', '-', 'nuee', '-', 'nuee', ',', 'fegee', '.'], ['pekee', '-', 'nuee', '-', 'nuee', ',', 'erromangoan', '.'], ['extracts', '(', 'supplied', 'by', 'a', 'sub', '-', 'sub', '-', 'librarian', ').'], ['it', 'will', 'be', 'seen', 'that', 'this', 'mere', 'painstaking', 'burrower', 'and', 'grub', '-', 'worm', 'of', 'a', 'poor', 'devil', 'of', 'a', 'sub', '-', 'sub', 'appears', 'to', 'have', 'gone', 'through', 'the', 'long', 'vaticans', 'and', 'street', '-', 'stalls', 'of', 'the', 'earth', ',', 'picking', 'up', 'whatever', 'random', 'allusions', 'to', 'whales', 'he', 'could', 'anyways', 'find', 'in', 'any', 'book', 'whatsoever', ',', 'sacred', 'or', 'profane', '.'], ['therefore', 'you', 'must', 'not', ',', 'in', 'every', 'case', 'at', 'least', ',', 'take', 'the', 'higgledy', '-', 'piggledy', 'whale', 'statements', ',', 'however', 'authentic', ',', 'in', 'these', 'extracts', ',', 'for', 'veritable', 'gospel', 'cetology', '.'], ['far', 'from', 'it', '.'], ['as', 'touching', 'the', 'ancient', 'authors', 'generally', ',', 'as', 'well', 'as', 'the', 'poets', 'here', 'appearing', ',', 'these', 'extracts', 'are', 'solely', 'valuable', 'or', 'entertaining', ',', 'as', 'affording', 'a', 'glancing', 'bird', \"'\", 's', 'eye', 'view', 'of', 'what', 'has', 'been', 'promiscuously', 'said', ',', 'thought', ',', 'fancied', ',', 'and', 'sung', 'of', 'leviathan', ',', 'by', 'many', 'nations', 'and', 'generations', ',', 'including', 'our', 'own', '.'], ['so', 'fare', 'thee', 'well', ',', 'poor', 'devil', 'of', 'a', 'sub', '-', 'sub', ',', 'whose', 'commentator', 'i', 'am', '.'], ['thou', 'belongest', 'to', 'that', 'hopeless', ',', 'sallow', 'tribe', 'which', 'no', 'wine', 'of', 'this', 'world', 'will', 'ever', 'warm', ';', 'and', 'for', 'whom', 'even', 'pale', 'sherry', 'would', 'be', 'too', 'rosy', '-', 'strong', ';', 'but', 'with', 'whom', 'one', 'sometimes', 'loves', 'to', 'sit', ',', 'and', 'feel', 'poor', '-', 'devilish', ',', 'too', ';', 'and', 'grow', 'convivial', 'upon', 'tears', ';', 'and', 'say', 'to', 'them', 'bluntly', ',', 'with', 'full', 'eyes', 'and', 'empty', 'glasses', ',', 'and', 'in', 'not', 'altogether', 'unpleasant', 'sadness', '--', 'give', 'it', 'up', ',', 'sub', '-', 'subs', '!'], ['for', 'by', 'how', 'much', 'the', 'more', 'pains', 'ye', 'take', 'to', 'please', 'the', 'world', ',', 'by', 'so', 'much', 'the', 'more', 'shall', 'ye', 'for', 'ever', 'go', 'thankless', '!'], ['would', 'that', 'i', 'could', 'clear', 'out', 'hampton', 'court', 'and', 'the', 'tuileries', 'for', 'ye', '!'], ['but', 'gulp', 'down', 'your', 'tears', 'and', 'hie', 'aloft', 'to', 'the', 'royal', '-', 'mast', 'with', 'your', 'hearts', ';', 'for', 'your', 'friends', 'who', 'have', 'gone', 'before', 'are', 'clearing', 'out', 'the', 'seven', '-', 'storied', 'heavens', ',', 'and', 'making', 'refugees', 'of', 'long', '-', 'pampered', 'gabriel', ',', 'michael', ',', 'and', 'raphael', ',', 'against', 'your', 'coming', '.'], ['here', 'ye', 'strike', 'but', 'splintered', 'hearts', 'together', '--', 'there', ',', 'ye', 'shall', 'strike', 'unsplinterable', 'glasses', '!'], ['extracts', '.'], ['\"', 'and', 'god', 'created', 'great', 'whales', '.\"'], ['--', 'genesis', '.'], ['\"', 'leviathan', 'maketh', 'a', 'path', 'to', 'shine', 'after', 'him', ';', 'one', 'would', 'think', 'the', 'deep', 'to', 'be', 'hoary', '.\"'], ['--', 'job', '.'], ['\"', 'now', 'the', 'lord', 'had', 'prepared', 'a', 'great', 'fish', 'to', 'swallow', 'up', 'jonah', '.\"'], ['--', 'jonah', '.'], ['\"', 'there', 'go', 'the', 'ships', ';', 'there', 'is', 'that', 'leviathan', 'whom', 'thou', 'hast', 'made', 'to', 'play', 'therein', '.\"'], ['--', 'psalms', '.'], ['\"', 'in', 'that', 'day', ',', 'the', 'lord', 'with', 'his', 'sore', ',', 'and', 'great', ',', 'and', 'strong', 'sword', ',', 'shall', 'punish', 'leviathan', 'the', 'piercing', 'serpent', ',', 'even', 'leviathan', 'that', 'crooked', 'serpent', ';', 'and', 'he', 'shall', 'slay', 'the', 'dragon', 'that', 'is', 'in', 'the', 'sea', '.\"'], ['--', 'isaiah'], ['\"', 'and', 'what', 'thing', 'soever', 'besides', 'cometh', 'within', 'the', 'chaos', 'of', 'this', 'monster', \"'\", 's', 'mouth', ',', 'be', 'it', 'beast', ',', 'boat', ',', 'or', 'stone', ',', 'down', 'it', 'goes', 'all', 'incontinently', 'that', 'foul', 'great', 'swallow', 'of', 'his', ',', 'and', 'perisheth', 'in', 'the', 'bottomless', 'gulf', 'of', 'his', 'paunch', '.\"'], ['--', 'holland', \"'\", 's', 'plutarch', \"'\", 's', 'morals', '.'], ['\"', 'the', 'indian', 'sea', 'breedeth', 'the', 'most', 'and', 'the', 'biggest', 'fishes', 'that', 'are', ':', 'among', 'which', 'the', 'whales', 'and', 'whirlpooles', 'called', 'balaene', ',', 'take', 'up', 'as', 'much', 'in', 'length', 'as', 'four', 'acres', 'or', 'arpens', 'of', 'land', '.\"'], ['--', 'holland', \"'\", 's', 'pliny', '.'], ['\"', 'scarcely', 'had', 'we', 'proceeded', 'two', 'days', 'on', 'the', 'sea', ',', 'when', 'about', 'sunrise', 'a', 'great', 'many', 'whales', 'and', 'other', 'monsters', 'of', 'the', 'sea', ',', 'appeared', '.'], ['among', 'the', 'former', ',', 'one', 'was', 'of', 'a', 'most', 'monstrous', 'size', '.'], ['...'], ['this', 'came', 'towards', 'us', ',', 'open', '-', 'mouthed', ',', 'raising', 'the', 'waves', 'on', 'all', 'sides', ',', 'and', 'beating', 'the', 'sea', 'before', 'him', 'into', 'a', 'foam', '.\"'], ['--', 'tooke', \"'\", 's', 'lucian', '.'], ['\"', 'the', 'true', 'history', '.\"'], ['\"', 'he', 'visited', 'this', 'country', 'also', 'with', 'a', 'view', 'of', 'catching', 'horse', '-', 'whales', ',', 'which', 'had', 'bones', 'of', 'very', 'great', 'value', 'for', 'their', 'teeth', ',', 'of', 'which', 'he', 'brought', 'some', 'to', 'the', 'king', '.'], ['...'], ['the', 'best', 'whales', 'were', 'catched', 'in', 'his', 'own', 'country', ',', 'of', 'which', 'some', 'were', 'forty', '-', 'eight', ',', 'some', 'fifty', 'yards', 'long', '.'], ['he', 'said', 'that', 'he', 'was', 'one', 'of', 'six', 'who', 'had', 'killed', 'sixty', 'in', 'two', 'days', '.\"'], ['--', 'other', 'or', 'octher', \"'\", 's', 'verbal', 'narrative', 'taken', 'down', 'from', 'his', 'mouth', 'by', 'king', 'alfred', ',', 'a', '.', 'd', '.', '890', '.'], ['\"', 'and', 'whereas', 'all', 'the', 'other', 'things', ',', 'whether', 'beast', 'or', 'vessel', ',', 'that', 'enter', 'into', 'the', 'dreadful', 'gulf', 'of', 'this', 'monster', \"'\", 's', '(', 'whale', \"'\", 's', ')', 'mouth', ',', 'are', 'immediately', 'lost', 'and', 'swallowed', 'up', ',', 'the', 'sea', '-', 'gudgeon', 'retires', 'into', 'it', 'in', 'great', 'security', ',', 'and', 'there', 'sleeps', '.\"'], ['--', 'montaigne', '.'], ['--', 'apology', 'for', 'raimond', 'sebond', '.'], ['\"', 'let', 'us', 'fly', ',', 'let', 'us', 'fly', '!'], ['old', 'nick', 'take', 'me', 'if', 'is', 'not', 'leviathan', 'described', 'by', 'the', 'noble', 'prophet', 'moses', 'in', 'the', 'life', 'of', 'patient', 'job', '.\"'], ['--', 'rabelais', '.'], ['\"', 'this', 'whale', \"'\", 's', 'liver', 'was', 'two', 'cartloads', '.\"'], ['--', 'stowe', \"'\", 's', 'annals', '.'], ['\"', 'the', 'great', 'leviathan', 'that', 'maketh', 'the', 'seas', 'to', 'seethe', 'like', 'boiling', 'pan', '.\"'], ['--', 'lord', 'bacon', \"'\", 's', 'version', 'of', 'the', 'psalms', '.'], ['\"', 'touching', 'that', 'monstrous', 'bulk', 'of', 'the', 'whale', 'or', 'ork', 'we', 'have', 'received', 'nothing', 'certain', '.'], ['they', 'grow', 'exceeding', 'fat', ',', 'insomuch', 'that', 'an', 'incredible', 'quantity', 'of', 'oil', 'will', 'be', 'extracted', 'out', 'of', 'one', 'whale', '.\"'], ['--', 'ibid', '.'], ['\"', 'history', 'of', 'life', 'and', 'death', '.\"'], ['\"', 'the', 'sovereignest', 'thing', 'on', 'earth', 'is', 'parmacetti', 'for', 'an', 'inward', 'bruise', '.\"'], ['--', 'king', 'henry', '.'], ['\"', 'very', 'like', 'a', 'whale', '.\"'], ['--', 'hamlet', '.'], ['\"', 'which', 'to', 'secure', ',', 'no', 'skill', 'of', 'leach', \"'\", 's', 'art', 'mote', 'him', 'availle', ',', 'but', 'to', 'returne', 'againe', 'to', 'his', 'wound', \"'\", 's', 'worker', ',', 'that', 'with', 'lowly', 'dart', ',', 'dinting', 'his', 'breast', ',', 'had', 'bred', 'his', 'restless', 'paine', ',', 'like', 'as', 'the', 'wounded', 'whale', 'to', 'shore', 'flies', 'thro', \"'\", 'the', 'maine', '.\"'], ['--', 'the', 'faerie', 'queen', '.'], ['\"', 'immense', 'as', 'whales', ',', 'the', 'motion', 'of', 'whose', 'vast', 'bodies', 'can', 'in', 'a', 'peaceful', 'calm', 'trouble', 'the', 'ocean', 'til', 'it', 'boil', '.\"'], ['--', 'sir', 'william', 'davenant', '.'], ['preface', 'to', 'gondibert', '.'], ['\"', 'what', 'spermacetti', 'is', ',', 'men', 'might', 'justly', 'doubt', ',', 'since', 'the', 'learned', 'hosmannus', 'in', 'his', 'work', 'of', 'thirty', 'years', ',', 'saith', 'plainly', ',', 'nescio', 'quid', 'sit', '.\"'], ['--', 'sir', 't', '.', 'browne', '.'], ['of', 'sperma', 'ceti', 'and', 'the', 'sperma', 'ceti', 'whale', '.'], ['vide', 'his', 'v', '.', 'e', '.'], ['\"', 'like', 'spencer', \"'\", 's', 'talus', 'with', 'his', 'modern', 'flail', 'he', 'threatens', 'ruin', 'with', 'his', 'ponderous', 'tail', '.'], ['...', 'their', 'fixed', 'jav', \"'\", 'lins', 'in', 'his', 'side', 'he', 'wears', ',', 'and', 'on', 'his', 'back', 'a', 'grove', 'of', 'pikes', 'appears', '.\"'], ['--', 'waller', \"'\", 's', 'battle', 'of', 'the', 'summer', 'islands', '.'], ['\"', 'by', 'art', 'is', 'created', 'that', 'great', 'leviathan', ',', 'called', 'a', 'commonwealth', 'or', 'state', '--(', 'in', 'latin', ',', 'civitas', ')', 'which', 'is', 'but', 'an', 'artificial', 'man', '.\"']]\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'moby', 'dick', 'by', 'herman', 'melville', '1851', ']', 'etymology', '.', '(', 'supplied', 'by', 'a', 'late', 'consumptive', 'usher', 'to', 'a', 'grammar', 'school', ')', 'the', 'pale', 'usher', '--', 'threadbare', 'in', 'coat', ',', 'heart', ',', 'body', ',', 'and', 'brain', ';', 'i', 'see', 'him', 'now', '.', 'he', 'was', 'ever', 'dusting', 'his', 'old', 'lexicons', 'and', 'grammars', ',', 'with', 'a', 'queer', 'handkerchief', ',', 'mockingly', 'embellished', 'with', 'all', 'the', 'gay', 'flags', 'of', 'all', 'the', 'known', 'nations', 'of', 'the', 'world', '.', 'he', 'loved', 'to', 'dust', 'his', 'old', 'grammars', ';', 'it', 'somehow', 'mildly', 'reminded', 'him', 'of', 'his', 'mortality', '.', '\"', 'while', 'you', 'take', 'in', 'hand', 'to', 'school', 'others', ',', 'and', 'to', 'teach', 'them', 'by', 'what', 'name', 'a', 'whale', '-', 'fish', 'is', 'to', 'be', 'called', 'in', 'our', 'tongue', 'leaving', 'out', ',', 'through', 'ignorance', ',', 'the', 'letter', 'h', ',', 'which', 'almost', 'alone', 'maketh', 'the', 'signification', 'of', 'the', 'word', ',', 'you', 'deliver', 'that', 'which', 'is', 'not', 'true', '.\"', '--', 'hackluyt', '\"', 'whale', '.', '...', 'sw', '.', 'and', 'dan', '.', 'hval', '.', 'this', 'animal', 'is', 'named', 'from', 'roundness', 'or', 'rolling', ';', 'for', 'in', 'dan', '.', 'hvalt', 'is', 'arched', 'or', 'vaulted', '.\"', '--', 'webster', \"'\", 's', 'dictionary', '\"', 'whale', '.', '...', 'it', 'is', 'more', 'immediately', 'from', 'the', 'dut', '.', 'and', 'ger', '.', 'wallen', ';', 'a', '.', 's', '.', 'walw', '-', 'ian', ',', 'to', 'roll', ',', 'to', 'wallow', '.\"', '--', 'richardson', \"'\", 's', 'dictionary', 'ketos', ',', 'greek', '.', 'cetus', ',', 'latin', '.', 'whoel', ',', 'anglo', '-', 'saxon', '.', 'hvalt', ',', 'danish', '.', 'wal', ',', 'dutch', '.', 'hwal', ',', 'swedish', '.', 'whale', ',', 'icelandic', '.', 'whale', ',', 'english', '.', 'baleine', ',', 'french', '.', 'ballena', ',', 'spanish', '.', 'pekee', '-', 'nuee', '-', 'nuee', ',', 'fegee', '.', 'pekee', '-', 'nuee', '-', 'nuee', ',', 'erromangoan', '.', 'extracts', '(', 'supplied', 'by', 'a', 'sub', '-', 'sub', '-', 'librarian', ').', 'it', 'will', 'be', 'seen', 'that', 'this', 'mere', 'painstaking', 'burrower', 'and', 'grub', '-', 'worm', 'of', 'a', 'poor', 'devil', 'of', 'a', 'sub', '-', 'sub', 'appears', 'to', 'have', 'gone', 'through', 'the', 'long', 'vaticans', 'and', 'street', '-', 'stalls', 'of', 'the', 'earth', ',', 'picking', 'up', 'whatever', 'random', 'allusions', 'to', 'whales', 'he', 'could', 'anyways', 'find', 'in', 'any', 'book', 'whatsoever', ',', 'sacred', 'or', 'profane', '.', 'therefore', 'you', 'must', 'not', ',', 'in', 'every', 'case', 'at', 'least', ',', 'take', 'the', 'higgledy', '-', 'piggledy', 'whale', 'statements', ',', 'however', 'authentic', ',', 'in', 'these', 'extracts', ',', 'for', 'veritable', 'gospel', 'cetology', '.', 'far', 'from', 'it', '.', 'as', 'touching', 'the', 'ancient', 'authors', 'generally', ',', 'as', 'well', 'as', 'the', 'poets', 'here', 'appearing', ',', 'these', 'extracts', 'are', 'solely', 'valuable', 'or', 'entertaining', ',', 'as', 'affording', 'a', 'glancing', 'bird', \"'\", 's', 'eye', 'view', 'of', 'what', 'has', 'been', 'promiscuously', 'said', ',', 'thought', ',', 'fancied', ',', 'and', 'sung', 'of', 'leviathan', ',', 'by', 'many', 'nations', 'and', 'generations', ',', 'including', 'our', 'own', '.', 'so', 'fare', 'thee', 'well', ',', 'poor', 'devil', 'of', 'a', 'sub', '-', 'sub', ',', 'whose', 'commentator', 'i', 'am', '.', 'thou', 'belongest', 'to', 'that', 'hopeless', ',', 'sallow', 'tribe', 'which', 'no', 'wine', 'of', 'this', 'world', 'will', 'ever', 'warm', ';', 'and', 'for', 'whom', 'even', 'pale', 'sherry', 'would', 'be', 'too', 'rosy', '-', 'strong', ';', 'but', 'with', 'whom', 'one', 'sometimes', 'loves', 'to', 'sit', ',', 'and', 'feel', 'poor', '-', 'devilish', ',', 'too', ';', 'and', 'grow', 'convivial', 'upon', 'tears', ';', 'and', 'say', 'to', 'them', 'bluntly', ',', 'with', 'full', 'eyes', 'and', 'empty', 'glasses', ',', 'and', 'in', 'not', 'altogether', 'unpleasant', 'sadness', '--', 'give', 'it', 'up', ',', 'sub', '-', 'subs', '!', 'for', 'by', 'how', 'much', 'the', 'more', 'pains', 'ye', 'take', 'to', 'please', 'the', 'world', ',', 'by', 'so', 'much', 'the', 'more', 'shall', 'ye', 'for', 'ever', 'go', 'thankless', '!', 'would', 'that', 'i', 'could', 'clear', 'out', 'hampton', 'court', 'and', 'the', 'tuileries', 'for', 'ye', '!', 'but', 'gulp', 'down', 'your', 'tears', 'and', 'hie', 'aloft', 'to', 'the', 'royal', '-', 'mast', 'with', 'your', 'hearts', ';', 'for', 'your', 'friends', 'who', 'have', 'gone', 'before', 'are', 'clearing', 'out', 'the', 'seven', '-', 'storied', 'heavens', ',', 'and', 'making', 'refugees', 'of', 'long', '-', 'pampered', 'gabriel', ',', 'michael', ',', 'and', 'raphael', ',', 'against', 'your', 'coming', '.', 'here', 'ye', 'strike', 'but', 'splintered', 'hearts', 'together', '--', 'there', ',', 'ye', 'shall', 'strike', 'unsplinterable', 'glasses', '!', 'extracts', '.', '\"', 'and', 'god', 'created', 'great', 'whales', '.\"', '--', 'genesis', '.', '\"', 'leviathan', 'maketh', 'a', 'path', 'to', 'shine', 'after', 'him', ';', 'one', 'would', 'think', 'the', 'deep', 'to', 'be', 'hoary', '.\"', '--', 'job', '.', '\"', 'now', 'the', 'lord', 'had', 'prepared', 'a', 'great', 'fish', 'to', 'swallow', 'up', 'jonah', '.\"', '--', 'jonah', '.', '\"', 'there', 'go', 'the', 'ships', ';', 'there', 'is', 'that', 'leviathan', 'whom', 'thou', 'hast', 'made', 'to', 'play', 'therein', '.\"', '--', 'psalms', '.', '\"', 'in', 'that', 'day', ',', 'the', 'lord', 'with', 'his', 'sore', ',', 'and', 'great', ',', 'and', 'strong', 'sword', ',', 'shall', 'punish', 'leviathan', 'the', 'piercing', 'serpent', ',', 'even', 'leviathan', 'that', 'crooked', 'serpent', ';', 'and', 'he', 'shall', 'slay', 'the', 'dragon', 'that', 'is', 'in', 'the', 'sea', '.\"', '--', 'isaiah', '\"', 'and', 'what', 'thing', 'soever', 'besides', 'cometh', 'within', 'the', 'chaos', 'of', 'this', 'monster', \"'\", 's', 'mouth', ',', 'be', 'it', 'beast', ',', 'boat', ',', 'or', 'stone', ',', 'down', 'it', 'goes', 'all', 'incontinently', 'that', 'foul', 'great', 'swallow', 'of', 'his', ',', 'and', 'perisheth', 'in', 'the', 'bottomless', 'gulf', 'of', 'his', 'paunch', '.\"', '--', 'holland', \"'\", 's', 'plutarch', \"'\", 's', 'morals', '.', '\"', 'the', 'indian', 'sea', 'breedeth', 'the', 'most', 'and', 'the', 'biggest', 'fishes', 'that', 'are', ':', 'among', 'which', 'the', 'whales', 'and', 'whirlpooles', 'called', 'balaene', ',', 'take', 'up', 'as', 'much', 'in', 'length', 'as', 'four', 'acres', 'or', 'arpens', 'of', 'land', '.\"', '--', 'holland', \"'\", 's', 'pliny', '.', '\"', 'scarcely', 'had', 'we', 'proceeded', 'two', 'days', 'on', 'the', 'sea', ',', 'when', 'about', 'sunrise', 'a', 'great', 'many', 'whales', 'and', 'other', 'monsters', 'of', 'the', 'sea', ',', 'appeared', '.', 'among', 'the', 'former', ',', 'one', 'was', 'of', 'a', 'most', 'monstrous', 'size', '.', '...', 'this', 'came', 'towards', 'us', ',', 'open', '-', 'mouthed', ',', 'raising', 'the', 'waves', 'on', 'all', 'sides', ',', 'and', 'beating', 'the', 'sea', 'before', 'him', 'into', 'a', 'foam', '.\"', '--', 'tooke', \"'\", 's', 'lucian', '.', '\"', 'the', 'true', 'history', '.\"', '\"', 'he', 'visited', 'this', 'country', 'also', 'with', 'a', 'view', 'of', 'catching', 'horse', '-', 'whales', ',', 'which', 'had', 'bones', 'of', 'very', 'great', 'value', 'for', 'their', 'teeth', ',', 'of', 'which', 'he', 'brought', 'some', 'to', 'the', 'king', '.', '...', 'the', 'best', 'whales', 'were', 'catched', 'in', 'his', 'own', 'country', ',', 'of', 'which', 'some', 'were', 'forty', '-', 'eight', ',', 'some', 'fifty', 'yards', 'long', '.', 'he', 'said', 'that', 'he', 'was', 'one', 'of', 'six', 'who', 'had', 'killed', 'sixty', 'in', 'two', 'days', '.\"', '--', 'other', 'or', 'octher', \"'\", 's', 'verbal', 'narrative', 'taken', 'down', 'from', 'his', 'mouth', 'by', 'king', 'alfred', ',', 'a', '.', 'd', '.', '890', '.', '\"', 'and', 'whereas', 'all', 'the', 'other', 'things', ',', 'whether', 'beast', 'or', 'vessel', ',', 'that', 'enter', 'into', 'the', 'dreadful', 'gulf', 'of', 'this', 'monster', \"'\", 's', '(', 'whale', \"'\", 's', ')', 'mouth', ',', 'are', 'immediately', 'lost', 'and', 'swallowed', 'up', ',', 'the', 'sea', '-', 'gudgeon', 'retires', 'into', 'it', 'in', 'great', 'security', ',', 'and', 'there', 'sleeps', '.\"', '--', 'montaigne', '.', '--', 'apology', 'for', 'raimond', 'sebond', '.', '\"', 'let', 'us', 'fly', ',', 'let', 'us', 'fly', '!', 'old', 'nick', 'take', 'me', 'if', 'is', 'not', 'leviathan', 'described', 'by', 'the', 'noble', 'prophet', 'moses', 'in', 'the', 'life', 'of', 'patient', 'job', '.\"', '--', 'rabelais', '.', '\"', 'this', 'whale', \"'\", 's', 'liver', 'was', 'two', 'cartloads', '.\"', '--', 'stowe', \"'\", 's', 'annals', '.', '\"', 'the', 'great', 'leviathan', 'that', 'maketh', 'the', 'seas', 'to', 'seethe', 'like', 'boiling', 'pan', '.\"', '--', 'lord', 'bacon', \"'\", 's', 'version', 'of', 'the', 'psalms', '.', '\"', 'touching', 'that', 'monstrous', 'bulk', 'of', 'the', 'whale', 'or', 'ork', 'we', 'have', 'received', 'nothing', 'certain', '.', 'they', 'grow', 'exceeding', 'fat', ',', 'insomuch', 'that', 'an', 'incredible', 'quantity', 'of', 'oil', 'will', 'be', 'extracted', 'out', 'of', 'one', 'whale', '.\"', '--', 'ibid', '.', '\"', 'history', 'of', 'life', 'and', 'death', '.\"', '\"', 'the', 'sovereignest', 'thing', 'on', 'earth', 'is', 'parmacetti', 'for', 'an', 'inward', 'bruise', '.\"', '--', 'king', 'henry', '.', '\"', 'very', 'like', 'a', 'whale', '.\"', '--', 'hamlet', '.', '\"', 'which', 'to', 'secure', ',', 'no', 'skill', 'of', 'leach', \"'\", 's', 'art', 'mote', 'him', 'availle', ',', 'but', 'to', 'returne', 'againe', 'to', 'his', 'wound', \"'\", 's', 'worker', ',', 'that', 'with', 'lowly', 'dart', ',', 'dinting', 'his', 'breast', ',', 'had', 'bred', 'his', 'restless', 'paine', ',', 'like', 'as', 'the', 'wounded', 'whale', 'to', 'shore', 'flies', 'thro', \"'\", 'the', 'maine', '.\"', '--', 'the', 'faerie', 'queen', '.', '\"', 'immense', 'as', 'whales', ',', 'the', 'motion', 'of', 'whose', 'vast', 'bodies', 'can', 'in', 'a', 'peaceful', 'calm', 'trouble', 'the', 'ocean', 'til', 'it', 'boil', '.\"', '--', 'sir', 'william', 'davenant', '.', 'preface', 'to', 'gondibert', '.', '\"', 'what', 'spermacetti', 'is', ',', 'men', 'might', 'justly', 'doubt', ',', 'since', 'the', 'learned', 'hosmannus', 'in', 'his', 'work', 'of', 'thirty', 'years', ',', 'saith', 'plainly', ',', 'nescio', 'quid', 'sit', '.\"', '--', 'sir', 't', '.', 'browne', '.', 'of', 'sperma', 'ceti', 'and', 'the', 'sperma', 'ceti', 'whale', '.', 'vide', 'his', 'v', '.', 'e', '.', '\"', 'like', 'spencer', \"'\", 's', 'talus', 'with', 'his', 'modern', 'flail', 'he', 'threatens', 'ruin', 'with', 'his', 'ponderous', 'tail', '.', '...', 'their', 'fixed', 'jav', \"'\", 'lins', 'in', 'his', 'side', 'he', 'wears', ',', 'and', 'on', 'his', 'back', 'a', 'grove', 'of', 'pikes', 'appears', '.\"', '--', 'waller', \"'\", 's', 'battle', 'of', 'the', 'summer', 'islands', '.', '\"', 'by', 'art', 'is', 'created', 'that', 'great', 'leviathan', ',', 'called', 'a', 'commonwealth', 'or', 'state', '--(', 'in', 'latin', ',', 'civitas', ')', 'which', 'is', 'but', 'an', 'artificial', 'man', '.\"']\n"
     ]
    }
   ],
   "source": [
    "print(flatten(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = Counter(flatten(corpus))\n",
    "border = int(len(word_count) * 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({',': 96, '.': 66, 'the': 58, 'of': 36, 'and': 35, '--': 27, '\"': 26, '.\"': 26, 'to': 25, '-': 24, 'a': 21, 'in': 20, \"'\": 20, 's': 19, 'his': 17, 'that': 17, 'whale': 13, ';': 12, 'is': 12, 'by': 10, 'he': 10, 'with': 10, 'or': 10, 'for': 10, 'it': 9, 'which': 9, 'great': 9, 'this': 8, 'as': 8, 'leviathan': 8, 'sub': 7, 'whales': 7, 'be': 6, 'sea': 6, 'him': 5, 'all': 5, 'take': 5, '...': 5, 'up': 5, 'but': 5, 'one': 5, '!': 5, 'ye': 5, 'had': 5, 'was': 4, 'what': 4, 'out': 4, 'not': 4, 'from': 4, 'nuee': 4, 'extracts': 4, 'are': 4, 'shall': 4, 'your': 4, 'there': 4, 'on': 4, 'like': 4, '(': 3, ')': 3, 'i': 3, 'ever': 3, 'old': 3, 'world': 3, 'you': 3, 'called': 3, 'maketh': 3, 'more': 3, 'will': 3, 'poor': 3, 'have': 3, 'long': 3, 'whom': 3, 'would': 3, 'much': 3, 'down': 3, 'lord': 3, 'mouth': 3, 'two': 3, 'other': 3, 'us': 3, 'into': 3, 'some': 3, 'king': 3, 'an': 3, 'supplied': 2, 'usher': 2, 'school': 2, 'pale': 2, 'now': 2, 'grammars': 2, 'nations': 2, 'them': 2, 'fish': 2, 'our': 2, 'through': 2, 'true': 2, 'dan': 2, 'hvalt': 2, 'dictionary': 2, 'immediately': 2, 'latin': 2, 'pekee': 2, 'devil': 2, 'appears': 2, 'gone': 2, 'earth': 2, 'could': 2, 'these': 2, 'touching': 2, 'well': 2, 'here': 2, 'view': 2, 'said': 2, 'many': 2, 'own': 2, 'so': 2, 'whose': 2, 'thou': 2, 'no': 2, 'even': 2, 'too': 2, 'strong': 2, 'sit': 2, 'grow': 2, 'tears': 2, 'glasses': 2, 'go': 2, 'hearts': 2, 'who': 2, 'before': 2, 'strike': 2, 'created': 2, 'job': 2, 'swallow': 2, 'jonah': 2, 'psalms': 2, 'serpent': 2, 'thing': 2, 'monster': 2, 'beast': 2, 'gulf': 2, 'holland': 2, 'most': 2, 'among': 2, 'we': 2, 'days': 2, 'monstrous': 2, 'history': 2, 'country': 2, 'very': 2, 'their': 2, 'were': 2, 'let': 2, 'fly': 2, 'life': 2, 'art': 2, 'sir': 2, 'sperma': 2, 'ceti': 2, '[': 1, 'moby': 1, 'dick': 1, 'herman': 1, 'melville': 1, '1851': 1, ']': 1, 'etymology': 1, 'late': 1, 'consumptive': 1, 'grammar': 1, 'threadbare': 1, 'coat': 1, 'heart': 1, 'body': 1, 'brain': 1, 'see': 1, 'dusting': 1, 'lexicons': 1, 'queer': 1, 'handkerchief': 1, 'mockingly': 1, 'embellished': 1, 'gay': 1, 'flags': 1, 'known': 1, 'loved': 1, 'dust': 1, 'somehow': 1, 'mildly': 1, 'reminded': 1, 'mortality': 1, 'while': 1, 'hand': 1, 'others': 1, 'teach': 1, 'name': 1, 'tongue': 1, 'leaving': 1, 'ignorance': 1, 'letter': 1, 'h': 1, 'almost': 1, 'alone': 1, 'signification': 1, 'word': 1, 'deliver': 1, 'hackluyt': 1, 'sw': 1, 'hval': 1, 'animal': 1, 'named': 1, 'roundness': 1, 'rolling': 1, 'arched': 1, 'vaulted': 1, 'webster': 1, 'dut': 1, 'ger': 1, 'wallen': 1, 'walw': 1, 'ian': 1, 'roll': 1, 'wallow': 1, 'richardson': 1, 'ketos': 1, 'greek': 1, 'cetus': 1, 'whoel': 1, 'anglo': 1, 'saxon': 1, 'danish': 1, 'wal': 1, 'dutch': 1, 'hwal': 1, 'swedish': 1, 'icelandic': 1, 'english': 1, 'baleine': 1, 'french': 1, 'ballena': 1, 'spanish': 1, 'fegee': 1, 'erromangoan': 1, 'librarian': 1, ').': 1, 'seen': 1, 'mere': 1, 'painstaking': 1, 'burrower': 1, 'grub': 1, 'worm': 1, 'vaticans': 1, 'street': 1, 'stalls': 1, 'picking': 1, 'whatever': 1, 'random': 1, 'allusions': 1, 'anyways': 1, 'find': 1, 'any': 1, 'book': 1, 'whatsoever': 1, 'sacred': 1, 'profane': 1, 'therefore': 1, 'must': 1, 'every': 1, 'case': 1, 'at': 1, 'least': 1, 'higgledy': 1, 'piggledy': 1, 'statements': 1, 'however': 1, 'authentic': 1, 'veritable': 1, 'gospel': 1, 'cetology': 1, 'far': 1, 'ancient': 1, 'authors': 1, 'generally': 1, 'poets': 1, 'appearing': 1, 'solely': 1, 'valuable': 1, 'entertaining': 1, 'affording': 1, 'glancing': 1, 'bird': 1, 'eye': 1, 'has': 1, 'been': 1, 'promiscuously': 1, 'thought': 1, 'fancied': 1, 'sung': 1, 'generations': 1, 'including': 1, 'fare': 1, 'thee': 1, 'commentator': 1, 'am': 1, 'belongest': 1, 'hopeless': 1, 'sallow': 1, 'tribe': 1, 'wine': 1, 'warm': 1, 'sherry': 1, 'rosy': 1, 'sometimes': 1, 'loves': 1, 'feel': 1, 'devilish': 1, 'convivial': 1, 'upon': 1, 'say': 1, 'bluntly': 1, 'full': 1, 'eyes': 1, 'empty': 1, 'altogether': 1, 'unpleasant': 1, 'sadness': 1, 'give': 1, 'subs': 1, 'how': 1, 'pains': 1, 'please': 1, 'thankless': 1, 'clear': 1, 'hampton': 1, 'court': 1, 'tuileries': 1, 'gulp': 1, 'hie': 1, 'aloft': 1, 'royal': 1, 'mast': 1, 'friends': 1, 'clearing': 1, 'seven': 1, 'storied': 1, 'heavens': 1, 'making': 1, 'refugees': 1, 'pampered': 1, 'gabriel': 1, 'michael': 1, 'raphael': 1, 'against': 1, 'coming': 1, 'splintered': 1, 'together': 1, 'unsplinterable': 1, 'god': 1, 'genesis': 1, 'path': 1, 'shine': 1, 'after': 1, 'think': 1, 'deep': 1, 'hoary': 1, 'prepared': 1, 'ships': 1, 'hast': 1, 'made': 1, 'play': 1, 'therein': 1, 'day': 1, 'sore': 1, 'sword': 1, 'punish': 1, 'piercing': 1, 'crooked': 1, 'slay': 1, 'dragon': 1, 'isaiah': 1, 'soever': 1, 'besides': 1, 'cometh': 1, 'within': 1, 'chaos': 1, 'boat': 1, 'stone': 1, 'goes': 1, 'incontinently': 1, 'foul': 1, 'perisheth': 1, 'bottomless': 1, 'paunch': 1, 'plutarch': 1, 'morals': 1, 'indian': 1, 'breedeth': 1, 'biggest': 1, 'fishes': 1, ':': 1, 'whirlpooles': 1, 'balaene': 1, 'length': 1, 'four': 1, 'acres': 1, 'arpens': 1, 'land': 1, 'pliny': 1, 'scarcely': 1, 'proceeded': 1, 'when': 1, 'about': 1, 'sunrise': 1, 'monsters': 1, 'appeared': 1, 'former': 1, 'size': 1, 'came': 1, 'towards': 1, 'open': 1, 'mouthed': 1, 'raising': 1, 'waves': 1, 'sides': 1, 'beating': 1, 'foam': 1, 'tooke': 1, 'lucian': 1, 'visited': 1, 'also': 1, 'catching': 1, 'horse': 1, 'bones': 1, 'value': 1, 'teeth': 1, 'brought': 1, 'best': 1, 'catched': 1, 'forty': 1, 'eight': 1, 'fifty': 1, 'yards': 1, 'six': 1, 'killed': 1, 'sixty': 1, 'octher': 1, 'verbal': 1, 'narrative': 1, 'taken': 1, 'alfred': 1, 'd': 1, '890': 1, 'whereas': 1, 'things': 1, 'whether': 1, 'vessel': 1, 'enter': 1, 'dreadful': 1, 'lost': 1, 'swallowed': 1, 'gudgeon': 1, 'retires': 1, 'security': 1, 'sleeps': 1, 'montaigne': 1, 'apology': 1, 'raimond': 1, 'sebond': 1, 'nick': 1, 'me': 1, 'if': 1, 'described': 1, 'noble': 1, 'prophet': 1, 'moses': 1, 'patient': 1, 'rabelais': 1, 'liver': 1, 'cartloads': 1, 'stowe': 1, 'annals': 1, 'seas': 1, 'seethe': 1, 'boiling': 1, 'pan': 1, 'bacon': 1, 'version': 1, 'bulk': 1, 'ork': 1, 'received': 1, 'nothing': 1, 'certain': 1, 'they': 1, 'exceeding': 1, 'fat': 1, 'insomuch': 1, 'incredible': 1, 'quantity': 1, 'oil': 1, 'extracted': 1, 'ibid': 1, 'death': 1, 'sovereignest': 1, 'parmacetti': 1, 'inward': 1, 'bruise': 1, 'henry': 1, 'hamlet': 1, 'secure': 1, 'skill': 1, 'leach': 1, 'mote': 1, 'availle': 1, 'returne': 1, 'againe': 1, 'wound': 1, 'worker': 1, 'lowly': 1, 'dart': 1, 'dinting': 1, 'breast': 1, 'bred': 1, 'restless': 1, 'paine': 1, 'wounded': 1, 'shore': 1, 'flies': 1, 'thro': 1, 'maine': 1, 'faerie': 1, 'queen': 1, 'immense': 1, 'motion': 1, 'vast': 1, 'bodies': 1, 'can': 1, 'peaceful': 1, 'calm': 1, 'trouble': 1, 'ocean': 1, 'til': 1, 'boil': 1, 'william': 1, 'davenant': 1, 'preface': 1, 'gondibert': 1, 'spermacetti': 1, 'men': 1, 'might': 1, 'justly': 1, 'doubt': 1, 'since': 1, 'learned': 1, 'hosmannus': 1, 'work': 1, 'thirty': 1, 'years': 1, 'saith': 1, 'plainly': 1, 'nescio': 1, 'quid': 1, 't': 1, 'browne': 1, 'vide': 1, 'v': 1, 'e': 1, 'spencer': 1, 'talus': 1, 'modern': 1, 'flail': 1, 'threatens': 1, 'ruin': 1, 'ponderous': 1, 'tail': 1, 'fixed': 1, 'jav': 1, 'lins': 1, 'side': 1, 'wears': 1, 'back': 1, 'grove': 1, 'pikes': 1, 'waller': 1, 'battle': 1, 'summer': 1, 'islands': 1, 'commonwealth': 1, 'state': 1, '--(': 1, 'civitas': 1, 'artificial': 1, 'man': 1})\n"
     ]
    }
   ],
   "source": [
    "print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592\n"
     ]
    }
   ],
   "source": [
    "print(len(word_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 5 most common stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = word_count.most_common()[:border] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 96), ('.', 66), ('the', 58), ('of', 36), ('and', 35)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revstopwords= list(reversed(word_count.most_common()))[:border]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 1), ('artificial', 1), ('civitas', 1), ('--(', 1), ('state', 1)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revstopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Stopwords from unigram distribution's tails || Most used and least used are stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopwords = word_count.most_common()[:border] + list(reversed(word_count.most_common()))[:border]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 96),\n",
       " ('.', 66),\n",
       " ('the', 58),\n",
       " ('of', 36),\n",
       " ('and', 35),\n",
       " ('man', 1),\n",
       " ('artificial', 1),\n",
       " ('civitas', 1),\n",
       " ('--(', 1),\n",
       " ('state', 1)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = [s[0] for s in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '.', 'the', 'of', 'and', 'man', 'artificial', 'civitas', '--(', 'state']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = list(set(flatten(corpus)) - set(stopwords))\n",
    "vocab.append('<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bruise',\n",
       " 'baleine',\n",
       " 'school',\n",
       " 'ever',\n",
       " 'through',\n",
       " 'veritable',\n",
       " 'mockingly',\n",
       " 'hvalt',\n",
       " 'brain',\n",
       " 'six',\n",
       " 'art',\n",
       " 'erromangoan',\n",
       " 'which',\n",
       " 'immediately',\n",
       " 'catched',\n",
       " 'prepared',\n",
       " 'alone',\n",
       " 'ancient',\n",
       " 'they',\n",
       " 'ceti']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592 583\n"
     ]
    }
   ],
   "source": [
    "print(len(set(flatten(corpus))), len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2index = {'<UNK>' : 0} \n",
    "\n",
    "for vo in vocab:\n",
    "    if word2index.get(vo) is None:\n",
    "        word2index[vo] = len(word2index)\n",
    "\n",
    "index2word = {v:k for k, v in word2index.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!': 280,\n",
       " '\"': 54,\n",
       " \"'\": 55,\n",
       " '(': 243,\n",
       " ')': 545,\n",
       " ').': 147,\n",
       " '-': 374,\n",
       " '--': 382,\n",
       " '.\"': 123,\n",
       " '...': 317,\n",
       " '1851': 58,\n",
       " '890': 436,\n",
       " ':': 336,\n",
       " ';': 176,\n",
       " '<UNK>': 0,\n",
       " '[': 413,\n",
       " ']': 351,\n",
       " 'a': 532,\n",
       " 'about': 580,\n",
       " 'acres': 553,\n",
       " 'affording': 400,\n",
       " 'after': 459,\n",
       " 'againe': 240,\n",
       " 'against': 177,\n",
       " 'alfred': 402,\n",
       " 'all': 284,\n",
       " 'allusions': 260,\n",
       " 'almost': 153,\n",
       " 'aloft': 159,\n",
       " 'alone': 17,\n",
       " 'also': 396,\n",
       " 'altogether': 93,\n",
       " 'am': 26,\n",
       " 'among': 87,\n",
       " 'an': 311,\n",
       " 'ancient': 18,\n",
       " 'anglo': 397,\n",
       " 'animal': 273,\n",
       " 'annals': 469,\n",
       " 'any': 218,\n",
       " 'anyways': 442,\n",
       " 'apology': 427,\n",
       " 'appeared': 439,\n",
       " 'appearing': 56,\n",
       " 'appears': 508,\n",
       " 'arched': 254,\n",
       " 'are': 138,\n",
       " 'arpens': 103,\n",
       " 'art': 11,\n",
       " 'as': 562,\n",
       " 'at': 21,\n",
       " 'authentic': 470,\n",
       " 'authors': 249,\n",
       " 'availle': 133,\n",
       " 'back': 355,\n",
       " 'bacon': 47,\n",
       " 'balaene': 215,\n",
       " 'baleine': 2,\n",
       " 'ballena': 130,\n",
       " 'battle': 405,\n",
       " 'be': 206,\n",
       " 'beast': 404,\n",
       " 'beating': 431,\n",
       " 'been': 362,\n",
       " 'before': 557,\n",
       " 'belongest': 274,\n",
       " 'besides': 308,\n",
       " 'best': 72,\n",
       " 'biggest': 523,\n",
       " 'bird': 196,\n",
       " 'bluntly': 385,\n",
       " 'boat': 144,\n",
       " 'bodies': 540,\n",
       " 'body': 101,\n",
       " 'boil': 122,\n",
       " 'boiling': 236,\n",
       " 'bones': 117,\n",
       " 'book': 421,\n",
       " 'bottomless': 192,\n",
       " 'brain': 9,\n",
       " 'breast': 430,\n",
       " 'bred': 411,\n",
       " 'breedeth': 437,\n",
       " 'brought': 234,\n",
       " 'browne': 292,\n",
       " 'bruise': 1,\n",
       " 'bulk': 51,\n",
       " 'burrower': 338,\n",
       " 'but': 42,\n",
       " 'by': 290,\n",
       " 'called': 222,\n",
       " 'calm': 45,\n",
       " 'came': 158,\n",
       " 'can': 298,\n",
       " 'cartloads': 475,\n",
       " 'case': 31,\n",
       " 'catched': 15,\n",
       " 'catching': 504,\n",
       " 'certain': 403,\n",
       " 'ceti': 20,\n",
       " 'cetology': 264,\n",
       " 'cetus': 524,\n",
       " 'chaos': 142,\n",
       " 'clear': 433,\n",
       " 'clearing': 213,\n",
       " 'coat': 354,\n",
       " 'cometh': 408,\n",
       " 'coming': 480,\n",
       " 'commentator': 39,\n",
       " 'commonwealth': 387,\n",
       " 'consumptive': 344,\n",
       " 'convivial': 297,\n",
       " 'could': 500,\n",
       " 'country': 139,\n",
       " 'court': 175,\n",
       " 'created': 94,\n",
       " 'crooked': 456,\n",
       " 'd': 479,\n",
       " 'dan': 257,\n",
       " 'danish': 302,\n",
       " 'dart': 229,\n",
       " 'davenant': 128,\n",
       " 'day': 70,\n",
       " 'days': 579,\n",
       " 'death': 83,\n",
       " 'deep': 568,\n",
       " 'deliver': 441,\n",
       " 'described': 445,\n",
       " 'devil': 339,\n",
       " 'devilish': 478,\n",
       " 'dick': 576,\n",
       " 'dictionary': 464,\n",
       " 'dinting': 550,\n",
       " 'doubt': 85,\n",
       " 'down': 255,\n",
       " 'dragon': 554,\n",
       " 'dreadful': 235,\n",
       " 'dust': 466,\n",
       " 'dusting': 488,\n",
       " 'dut': 423,\n",
       " 'dutch': 293,\n",
       " 'e': 483,\n",
       " 'earth': 239,\n",
       " 'eight': 572,\n",
       " 'embellished': 575,\n",
       " 'empty': 220,\n",
       " 'english': 278,\n",
       " 'enter': 326,\n",
       " 'entertaining': 444,\n",
       " 'erromangoan': 12,\n",
       " 'etymology': 198,\n",
       " 'even': 542,\n",
       " 'ever': 4,\n",
       " 'every': 474,\n",
       " 'exceeding': 510,\n",
       " 'extracted': 155,\n",
       " 'extracts': 224,\n",
       " 'eye': 399,\n",
       " 'eyes': 190,\n",
       " 'faerie': 350,\n",
       " 'fancied': 265,\n",
       " 'far': 141,\n",
       " 'fare': 536,\n",
       " 'fat': 496,\n",
       " 'feel': 149,\n",
       " 'fegee': 506,\n",
       " 'fifty': 406,\n",
       " 'find': 570,\n",
       " 'fish': 511,\n",
       " 'fishes': 418,\n",
       " 'fixed': 60,\n",
       " 'flags': 306,\n",
       " 'flail': 30,\n",
       " 'flies': 223,\n",
       " 'fly': 41,\n",
       " 'foam': 457,\n",
       " 'for': 548,\n",
       " 'former': 289,\n",
       " 'forty': 242,\n",
       " 'foul': 538,\n",
       " 'four': 111,\n",
       " 'french': 253,\n",
       " 'friends': 124,\n",
       " 'from': 156,\n",
       " 'full': 534,\n",
       " 'gabriel': 197,\n",
       " 'gay': 349,\n",
       " 'generally': 270,\n",
       " 'generations': 425,\n",
       " 'genesis': 90,\n",
       " 'ger': 561,\n",
       " 'give': 313,\n",
       " 'glancing': 113,\n",
       " 'glasses': 577,\n",
       " 'go': 186,\n",
       " 'god': 27,\n",
       " 'goes': 386,\n",
       " 'gondibert': 286,\n",
       " 'gone': 232,\n",
       " 'gospel': 299,\n",
       " 'grammar': 357,\n",
       " 'grammars': 417,\n",
       " 'great': 384,\n",
       " 'greek': 371,\n",
       " 'grove': 200,\n",
       " 'grow': 174,\n",
       " 'grub': 458,\n",
       " 'gudgeon': 353,\n",
       " 'gulf': 146,\n",
       " 'gulp': 525,\n",
       " 'h': 98,\n",
       " 'hackluyt': 365,\n",
       " 'had': 381,\n",
       " 'hamlet': 345,\n",
       " 'hampton': 358,\n",
       " 'hand': 119,\n",
       " 'handkerchief': 263,\n",
       " 'has': 316,\n",
       " 'hast': 127,\n",
       " 'have': 335,\n",
       " 'he': 552,\n",
       " 'heart': 503,\n",
       " 'hearts': 34,\n",
       " 'heavens': 80,\n",
       " 'henry': 389,\n",
       " 'here': 84,\n",
       " 'herman': 50,\n",
       " 'hie': 452,\n",
       " 'higgledy': 75,\n",
       " 'him': 377,\n",
       " 'his': 73,\n",
       " 'history': 194,\n",
       " 'hoary': 285,\n",
       " 'holland': 227,\n",
       " 'hopeless': 373,\n",
       " 'horse': 57,\n",
       " 'hosmannus': 217,\n",
       " 'how': 530,\n",
       " 'however': 231,\n",
       " 'hval': 148,\n",
       " 'hvalt': 8,\n",
       " 'hwal': 171,\n",
       " 'i': 267,\n",
       " 'ian': 208,\n",
       " 'ibid': 491,\n",
       " 'icelandic': 401,\n",
       " 'if': 226,\n",
       " 'ignorance': 65,\n",
       " 'immediately': 14,\n",
       " 'immense': 407,\n",
       " 'in': 541,\n",
       " 'including': 121,\n",
       " 'incontinently': 167,\n",
       " 'incredible': 59,\n",
       " 'indian': 393,\n",
       " 'insomuch': 463,\n",
       " 'into': 283,\n",
       " 'inward': 481,\n",
       " 'is': 179,\n",
       " 'isaiah': 261,\n",
       " 'islands': 67,\n",
       " 'it': 368,\n",
       " 'jav': 199,\n",
       " 'job': 327,\n",
       " 'jonah': 86,\n",
       " 'justly': 455,\n",
       " 'ketos': 125,\n",
       " 'killed': 460,\n",
       " 'king': 378,\n",
       " 'known': 332,\n",
       " 'land': 204,\n",
       " 'late': 203,\n",
       " 'latin': 187,\n",
       " 'leach': 110,\n",
       " 'learned': 168,\n",
       " 'least': 181,\n",
       " 'leaving': 514,\n",
       " 'length': 348,\n",
       " 'let': 375,\n",
       " 'letter': 309,\n",
       " 'leviathan': 438,\n",
       " 'lexicons': 131,\n",
       " 'librarian': 328,\n",
       " 'life': 395,\n",
       " 'like': 333,\n",
       " 'lins': 246,\n",
       " 'liver': 166,\n",
       " 'long': 319,\n",
       " 'lord': 310,\n",
       " 'lost': 560,\n",
       " 'loved': 426,\n",
       " 'loves': 46,\n",
       " 'lowly': 564,\n",
       " 'lucian': 527,\n",
       " 'made': 271,\n",
       " 'maine': 287,\n",
       " 'maketh': 252,\n",
       " 'making': 266,\n",
       " 'many': 505,\n",
       " 'mast': 323,\n",
       " 'me': 334,\n",
       " 'melville': 501,\n",
       " 'men': 161,\n",
       " 'mere': 116,\n",
       " 'michael': 212,\n",
       " 'might': 49,\n",
       " 'mildly': 422,\n",
       " 'moby': 556,\n",
       " 'mockingly': 7,\n",
       " 'modern': 567,\n",
       " 'monster': 135,\n",
       " 'monsters': 23,\n",
       " 'monstrous': 356,\n",
       " 'montaigne': 160,\n",
       " 'morals': 517,\n",
       " 'more': 359,\n",
       " 'mortality': 390,\n",
       " 'moses': 535,\n",
       " 'most': 544,\n",
       " 'mote': 537,\n",
       " 'motion': 531,\n",
       " 'mouth': 276,\n",
       " 'mouthed': 347,\n",
       " 'much': 195,\n",
       " 'must': 380,\n",
       " 'name': 325,\n",
       " 'named': 574,\n",
       " 'narrative': 446,\n",
       " 'nations': 140,\n",
       " 'nescio': 465,\n",
       " 'nick': 558,\n",
       " 'no': 202,\n",
       " 'noble': 512,\n",
       " 'not': 547,\n",
       " 'nothing': 526,\n",
       " 'now': 137,\n",
       " 'nuee': 71,\n",
       " 'ocean': 189,\n",
       " 'octher': 383,\n",
       " 'oil': 337,\n",
       " 'old': 492,\n",
       " 'on': 275,\n",
       " 'one': 279,\n",
       " 'open': 428,\n",
       " 'or': 164,\n",
       " 'ork': 79,\n",
       " 'other': 182,\n",
       " 'others': 64,\n",
       " 'our': 546,\n",
       " 'out': 37,\n",
       " 'own': 233,\n",
       " 'paine': 363,\n",
       " 'pains': 571,\n",
       " 'painstaking': 241,\n",
       " 'pale': 497,\n",
       " 'pampered': 369,\n",
       " 'pan': 566,\n",
       " 'parmacetti': 48,\n",
       " 'path': 343,\n",
       " 'patient': 447,\n",
       " 'paunch': 134,\n",
       " 'peaceful': 468,\n",
       " 'pekee': 219,\n",
       " 'perisheth': 370,\n",
       " 'picking': 509,\n",
       " 'piercing': 277,\n",
       " 'piggledy': 230,\n",
       " 'pikes': 244,\n",
       " 'plainly': 315,\n",
       " 'play': 520,\n",
       " 'please': 451,\n",
       " 'pliny': 100,\n",
       " 'plutarch': 112,\n",
       " 'poets': 294,\n",
       " 'ponderous': 91,\n",
       " 'poor': 66,\n",
       " 'preface': 62,\n",
       " 'prepared': 16,\n",
       " 'proceeded': 145,\n",
       " 'profane': 533,\n",
       " 'promiscuously': 499,\n",
       " 'prophet': 415,\n",
       " 'psalms': 282,\n",
       " 'punish': 22,\n",
       " 'quantity': 341,\n",
       " 'queen': 295,\n",
       " 'queer': 104,\n",
       " 'quid': 314,\n",
       " 'rabelais': 296,\n",
       " 'raimond': 322,\n",
       " 'raising': 76,\n",
       " 'random': 435,\n",
       " 'raphael': 108,\n",
       " 'received': 185,\n",
       " 'refugees': 394,\n",
       " 'reminded': 513,\n",
       " 'restless': 63,\n",
       " 'retires': 489,\n",
       " 'returne': 165,\n",
       " 'richardson': 115,\n",
       " 'roll': 307,\n",
       " 'rolling': 569,\n",
       " 'rosy': 495,\n",
       " 'roundness': 331,\n",
       " 'royal': 225,\n",
       " 'ruin': 376,\n",
       " 's': 40,\n",
       " 'sacred': 539,\n",
       " 'sadness': 324,\n",
       " 'said': 453,\n",
       " 'saith': 88,\n",
       " 'sallow': 454,\n",
       " 'saxon': 528,\n",
       " 'say': 448,\n",
       " 'scarcely': 210,\n",
       " 'school': 3,\n",
       " 'sea': 409,\n",
       " 'seas': 498,\n",
       " 'sebond': 388,\n",
       " 'secure': 581,\n",
       " 'security': 162,\n",
       " 'see': 92,\n",
       " 'seen': 443,\n",
       " 'seethe': 109,\n",
       " 'serpent': 151,\n",
       " 'seven': 424,\n",
       " 'shall': 251,\n",
       " 'sherry': 484,\n",
       " 'shine': 105,\n",
       " 'ships': 573,\n",
       " 'shore': 521,\n",
       " 'side': 82,\n",
       " 'sides': 301,\n",
       " 'signification': 28,\n",
       " 'since': 391,\n",
       " 'sir': 256,\n",
       " 'sit': 493,\n",
       " 'six': 10,\n",
       " 'sixty': 340,\n",
       " 'size': 136,\n",
       " 'skill': 237,\n",
       " 'slay': 250,\n",
       " 'sleeps': 563,\n",
       " 'so': 77,\n",
       " 'soever': 432,\n",
       " 'solely': 25,\n",
       " 'some': 184,\n",
       " 'somehow': 352,\n",
       " 'sometimes': 44,\n",
       " 'sore': 262,\n",
       " 'sovereignest': 170,\n",
       " 'spanish': 379,\n",
       " 'spencer': 515,\n",
       " 'sperma': 486,\n",
       " 'spermacetti': 419,\n",
       " 'splintered': 329,\n",
       " 'stalls': 477,\n",
       " 'statements': 247,\n",
       " 'stone': 410,\n",
       " 'storied': 318,\n",
       " 'stowe': 555,\n",
       " 'street': 502,\n",
       " 'strike': 52,\n",
       " 'strong': 152,\n",
       " 'sub': 346,\n",
       " 'subs': 33,\n",
       " 'summer': 211,\n",
       " 'sung': 559,\n",
       " 'sunrise': 126,\n",
       " 'supplied': 420,\n",
       " 'sw': 120,\n",
       " 'swallow': 429,\n",
       " 'swallowed': 214,\n",
       " 'swedish': 201,\n",
       " 'sword': 360,\n",
       " 't': 516,\n",
       " 'tail': 53,\n",
       " 'take': 551,\n",
       " 'taken': 163,\n",
       " 'talus': 114,\n",
       " 'teach': 487,\n",
       " 'tears': 364,\n",
       " 'teeth': 172,\n",
       " 'thankless': 209,\n",
       " 'that': 99,\n",
       " 'thee': 549,\n",
       " 'their': 434,\n",
       " 'them': 518,\n",
       " 'there': 248,\n",
       " 'therefore': 462,\n",
       " 'therein': 188,\n",
       " 'these': 61,\n",
       " 'they': 19,\n",
       " 'thing': 106,\n",
       " 'things': 35,\n",
       " 'think': 291,\n",
       " 'thirty': 582,\n",
       " 'this': 543,\n",
       " 'thou': 207,\n",
       " 'thought': 259,\n",
       " 'threadbare': 507,\n",
       " 'threatens': 522,\n",
       " 'thro': 485,\n",
       " 'through': 5,\n",
       " 'til': 476,\n",
       " 'to': 578,\n",
       " 'together': 281,\n",
       " 'tongue': 169,\n",
       " 'too': 467,\n",
       " 'tooke': 288,\n",
       " 'touching': 191,\n",
       " 'towards': 29,\n",
       " 'tribe': 157,\n",
       " 'trouble': 473,\n",
       " 'true': 472,\n",
       " 'tuileries': 366,\n",
       " 'two': 367,\n",
       " 'unpleasant': 43,\n",
       " 'unsplinterable': 81,\n",
       " 'up': 392,\n",
       " 'upon': 193,\n",
       " 'us': 132,\n",
       " 'usher': 129,\n",
       " 'v': 221,\n",
       " 'valuable': 272,\n",
       " 'value': 178,\n",
       " 'vast': 216,\n",
       " 'vaticans': 24,\n",
       " 'vaulted': 398,\n",
       " 'verbal': 96,\n",
       " 'veritable': 6,\n",
       " 'version': 205,\n",
       " 'very': 304,\n",
       " 'vessel': 107,\n",
       " 'vide': 228,\n",
       " 'view': 440,\n",
       " 'visited': 102,\n",
       " 'wal': 300,\n",
       " 'wallen': 519,\n",
       " 'waller': 38,\n",
       " 'wallow': 69,\n",
       " 'walw': 258,\n",
       " 'warm': 74,\n",
       " 'was': 183,\n",
       " 'waves': 95,\n",
       " 'we': 416,\n",
       " 'wears': 320,\n",
       " 'webster': 330,\n",
       " 'well': 312,\n",
       " 'were': 482,\n",
       " 'whale': 68,\n",
       " 'whales': 414,\n",
       " 'what': 450,\n",
       " 'whatever': 173,\n",
       " 'whatsoever': 238,\n",
       " 'when': 494,\n",
       " 'whereas': 269,\n",
       " 'whether': 361,\n",
       " 'which': 13,\n",
       " 'while': 32,\n",
       " 'whirlpooles': 321,\n",
       " 'who': 529,\n",
       " 'whoel': 372,\n",
       " 'whom': 245,\n",
       " 'whose': 150,\n",
       " 'will': 154,\n",
       " 'william': 471,\n",
       " 'wine': 97,\n",
       " 'with': 305,\n",
       " 'within': 449,\n",
       " 'word': 303,\n",
       " 'work': 143,\n",
       " 'worker': 490,\n",
       " 'world': 180,\n",
       " 'worm': 565,\n",
       " 'would': 412,\n",
       " 'wound': 268,\n",
       " 'wounded': 118,\n",
       " 'yards': 461,\n",
       " 'ye': 89,\n",
       " 'years': 36,\n",
       " 'you': 78,\n",
       " 'your': 342}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<UNK>',\n",
       " 1: 'bruise',\n",
       " 2: 'baleine',\n",
       " 3: 'school',\n",
       " 4: 'ever',\n",
       " 5: 'through',\n",
       " 6: 'veritable',\n",
       " 7: 'mockingly',\n",
       " 8: 'hvalt',\n",
       " 9: 'brain',\n",
       " 10: 'six',\n",
       " 11: 'art',\n",
       " 12: 'erromangoan',\n",
       " 13: 'which',\n",
       " 14: 'immediately',\n",
       " 15: 'catched',\n",
       " 16: 'prepared',\n",
       " 17: 'alone',\n",
       " 18: 'ancient',\n",
       " 19: 'they',\n",
       " 20: 'ceti',\n",
       " 21: 'at',\n",
       " 22: 'punish',\n",
       " 23: 'monsters',\n",
       " 24: 'vaticans',\n",
       " 25: 'solely',\n",
       " 26: 'am',\n",
       " 27: 'god',\n",
       " 28: 'signification',\n",
       " 29: 'towards',\n",
       " 30: 'flail',\n",
       " 31: 'case',\n",
       " 32: 'while',\n",
       " 33: 'subs',\n",
       " 34: 'hearts',\n",
       " 35: 'things',\n",
       " 36: 'years',\n",
       " 37: 'out',\n",
       " 38: 'waller',\n",
       " 39: 'commentator',\n",
       " 40: 's',\n",
       " 41: 'fly',\n",
       " 42: 'but',\n",
       " 43: 'unpleasant',\n",
       " 44: 'sometimes',\n",
       " 45: 'calm',\n",
       " 46: 'loves',\n",
       " 47: 'bacon',\n",
       " 48: 'parmacetti',\n",
       " 49: 'might',\n",
       " 50: 'herman',\n",
       " 51: 'bulk',\n",
       " 52: 'strike',\n",
       " 53: 'tail',\n",
       " 54: '\"',\n",
       " 55: \"'\",\n",
       " 56: 'appearing',\n",
       " 57: 'horse',\n",
       " 58: '1851',\n",
       " 59: 'incredible',\n",
       " 60: 'fixed',\n",
       " 61: 'these',\n",
       " 62: 'preface',\n",
       " 63: 'restless',\n",
       " 64: 'others',\n",
       " 65: 'ignorance',\n",
       " 66: 'poor',\n",
       " 67: 'islands',\n",
       " 68: 'whale',\n",
       " 69: 'wallow',\n",
       " 70: 'day',\n",
       " 71: 'nuee',\n",
       " 72: 'best',\n",
       " 73: 'his',\n",
       " 74: 'warm',\n",
       " 75: 'higgledy',\n",
       " 76: 'raising',\n",
       " 77: 'so',\n",
       " 78: 'you',\n",
       " 79: 'ork',\n",
       " 80: 'heavens',\n",
       " 81: 'unsplinterable',\n",
       " 82: 'side',\n",
       " 83: 'death',\n",
       " 84: 'here',\n",
       " 85: 'doubt',\n",
       " 86: 'jonah',\n",
       " 87: 'among',\n",
       " 88: 'saith',\n",
       " 89: 'ye',\n",
       " 90: 'genesis',\n",
       " 91: 'ponderous',\n",
       " 92: 'see',\n",
       " 93: 'altogether',\n",
       " 94: 'created',\n",
       " 95: 'waves',\n",
       " 96: 'verbal',\n",
       " 97: 'wine',\n",
       " 98: 'h',\n",
       " 99: 'that',\n",
       " 100: 'pliny',\n",
       " 101: 'body',\n",
       " 102: 'visited',\n",
       " 103: 'arpens',\n",
       " 104: 'queer',\n",
       " 105: 'shine',\n",
       " 106: 'thing',\n",
       " 107: 'vessel',\n",
       " 108: 'raphael',\n",
       " 109: 'seethe',\n",
       " 110: 'leach',\n",
       " 111: 'four',\n",
       " 112: 'plutarch',\n",
       " 113: 'glancing',\n",
       " 114: 'talus',\n",
       " 115: 'richardson',\n",
       " 116: 'mere',\n",
       " 117: 'bones',\n",
       " 118: 'wounded',\n",
       " 119: 'hand',\n",
       " 120: 'sw',\n",
       " 121: 'including',\n",
       " 122: 'boil',\n",
       " 123: '.\"',\n",
       " 124: 'friends',\n",
       " 125: 'ketos',\n",
       " 126: 'sunrise',\n",
       " 127: 'hast',\n",
       " 128: 'davenant',\n",
       " 129: 'usher',\n",
       " 130: 'ballena',\n",
       " 131: 'lexicons',\n",
       " 132: 'us',\n",
       " 133: 'availle',\n",
       " 134: 'paunch',\n",
       " 135: 'monster',\n",
       " 136: 'size',\n",
       " 137: 'now',\n",
       " 138: 'are',\n",
       " 139: 'country',\n",
       " 140: 'nations',\n",
       " 141: 'far',\n",
       " 142: 'chaos',\n",
       " 143: 'work',\n",
       " 144: 'boat',\n",
       " 145: 'proceeded',\n",
       " 146: 'gulf',\n",
       " 147: ').',\n",
       " 148: 'hval',\n",
       " 149: 'feel',\n",
       " 150: 'whose',\n",
       " 151: 'serpent',\n",
       " 152: 'strong',\n",
       " 153: 'almost',\n",
       " 154: 'will',\n",
       " 155: 'extracted',\n",
       " 156: 'from',\n",
       " 157: 'tribe',\n",
       " 158: 'came',\n",
       " 159: 'aloft',\n",
       " 160: 'montaigne',\n",
       " 161: 'men',\n",
       " 162: 'security',\n",
       " 163: 'taken',\n",
       " 164: 'or',\n",
       " 165: 'returne',\n",
       " 166: 'liver',\n",
       " 167: 'incontinently',\n",
       " 168: 'learned',\n",
       " 169: 'tongue',\n",
       " 170: 'sovereignest',\n",
       " 171: 'hwal',\n",
       " 172: 'teeth',\n",
       " 173: 'whatever',\n",
       " 174: 'grow',\n",
       " 175: 'court',\n",
       " 176: ';',\n",
       " 177: 'against',\n",
       " 178: 'value',\n",
       " 179: 'is',\n",
       " 180: 'world',\n",
       " 181: 'least',\n",
       " 182: 'other',\n",
       " 183: 'was',\n",
       " 184: 'some',\n",
       " 185: 'received',\n",
       " 186: 'go',\n",
       " 187: 'latin',\n",
       " 188: 'therein',\n",
       " 189: 'ocean',\n",
       " 190: 'eyes',\n",
       " 191: 'touching',\n",
       " 192: 'bottomless',\n",
       " 193: 'upon',\n",
       " 194: 'history',\n",
       " 195: 'much',\n",
       " 196: 'bird',\n",
       " 197: 'gabriel',\n",
       " 198: 'etymology',\n",
       " 199: 'jav',\n",
       " 200: 'grove',\n",
       " 201: 'swedish',\n",
       " 202: 'no',\n",
       " 203: 'late',\n",
       " 204: 'land',\n",
       " 205: 'version',\n",
       " 206: 'be',\n",
       " 207: 'thou',\n",
       " 208: 'ian',\n",
       " 209: 'thankless',\n",
       " 210: 'scarcely',\n",
       " 211: 'summer',\n",
       " 212: 'michael',\n",
       " 213: 'clearing',\n",
       " 214: 'swallowed',\n",
       " 215: 'balaene',\n",
       " 216: 'vast',\n",
       " 217: 'hosmannus',\n",
       " 218: 'any',\n",
       " 219: 'pekee',\n",
       " 220: 'empty',\n",
       " 221: 'v',\n",
       " 222: 'called',\n",
       " 223: 'flies',\n",
       " 224: 'extracts',\n",
       " 225: 'royal',\n",
       " 226: 'if',\n",
       " 227: 'holland',\n",
       " 228: 'vide',\n",
       " 229: 'dart',\n",
       " 230: 'piggledy',\n",
       " 231: 'however',\n",
       " 232: 'gone',\n",
       " 233: 'own',\n",
       " 234: 'brought',\n",
       " 235: 'dreadful',\n",
       " 236: 'boiling',\n",
       " 237: 'skill',\n",
       " 238: 'whatsoever',\n",
       " 239: 'earth',\n",
       " 240: 'againe',\n",
       " 241: 'painstaking',\n",
       " 242: 'forty',\n",
       " 243: '(',\n",
       " 244: 'pikes',\n",
       " 245: 'whom',\n",
       " 246: 'lins',\n",
       " 247: 'statements',\n",
       " 248: 'there',\n",
       " 249: 'authors',\n",
       " 250: 'slay',\n",
       " 251: 'shall',\n",
       " 252: 'maketh',\n",
       " 253: 'french',\n",
       " 254: 'arched',\n",
       " 255: 'down',\n",
       " 256: 'sir',\n",
       " 257: 'dan',\n",
       " 258: 'walw',\n",
       " 259: 'thought',\n",
       " 260: 'allusions',\n",
       " 261: 'isaiah',\n",
       " 262: 'sore',\n",
       " 263: 'handkerchief',\n",
       " 264: 'cetology',\n",
       " 265: 'fancied',\n",
       " 266: 'making',\n",
       " 267: 'i',\n",
       " 268: 'wound',\n",
       " 269: 'whereas',\n",
       " 270: 'generally',\n",
       " 271: 'made',\n",
       " 272: 'valuable',\n",
       " 273: 'animal',\n",
       " 274: 'belongest',\n",
       " 275: 'on',\n",
       " 276: 'mouth',\n",
       " 277: 'piercing',\n",
       " 278: 'english',\n",
       " 279: 'one',\n",
       " 280: '!',\n",
       " 281: 'together',\n",
       " 282: 'psalms',\n",
       " 283: 'into',\n",
       " 284: 'all',\n",
       " 285: 'hoary',\n",
       " 286: 'gondibert',\n",
       " 287: 'maine',\n",
       " 288: 'tooke',\n",
       " 289: 'former',\n",
       " 290: 'by',\n",
       " 291: 'think',\n",
       " 292: 'browne',\n",
       " 293: 'dutch',\n",
       " 294: 'poets',\n",
       " 295: 'queen',\n",
       " 296: 'rabelais',\n",
       " 297: 'convivial',\n",
       " 298: 'can',\n",
       " 299: 'gospel',\n",
       " 300: 'wal',\n",
       " 301: 'sides',\n",
       " 302: 'danish',\n",
       " 303: 'word',\n",
       " 304: 'very',\n",
       " 305: 'with',\n",
       " 306: 'flags',\n",
       " 307: 'roll',\n",
       " 308: 'besides',\n",
       " 309: 'letter',\n",
       " 310: 'lord',\n",
       " 311: 'an',\n",
       " 312: 'well',\n",
       " 313: 'give',\n",
       " 314: 'quid',\n",
       " 315: 'plainly',\n",
       " 316: 'has',\n",
       " 317: '...',\n",
       " 318: 'storied',\n",
       " 319: 'long',\n",
       " 320: 'wears',\n",
       " 321: 'whirlpooles',\n",
       " 322: 'raimond',\n",
       " 323: 'mast',\n",
       " 324: 'sadness',\n",
       " 325: 'name',\n",
       " 326: 'enter',\n",
       " 327: 'job',\n",
       " 328: 'librarian',\n",
       " 329: 'splintered',\n",
       " 330: 'webster',\n",
       " 331: 'roundness',\n",
       " 332: 'known',\n",
       " 333: 'like',\n",
       " 334: 'me',\n",
       " 335: 'have',\n",
       " 336: ':',\n",
       " 337: 'oil',\n",
       " 338: 'burrower',\n",
       " 339: 'devil',\n",
       " 340: 'sixty',\n",
       " 341: 'quantity',\n",
       " 342: 'your',\n",
       " 343: 'path',\n",
       " 344: 'consumptive',\n",
       " 345: 'hamlet',\n",
       " 346: 'sub',\n",
       " 347: 'mouthed',\n",
       " 348: 'length',\n",
       " 349: 'gay',\n",
       " 350: 'faerie',\n",
       " 351: ']',\n",
       " 352: 'somehow',\n",
       " 353: 'gudgeon',\n",
       " 354: 'coat',\n",
       " 355: 'back',\n",
       " 356: 'monstrous',\n",
       " 357: 'grammar',\n",
       " 358: 'hampton',\n",
       " 359: 'more',\n",
       " 360: 'sword',\n",
       " 361: 'whether',\n",
       " 362: 'been',\n",
       " 363: 'paine',\n",
       " 364: 'tears',\n",
       " 365: 'hackluyt',\n",
       " 366: 'tuileries',\n",
       " 367: 'two',\n",
       " 368: 'it',\n",
       " 369: 'pampered',\n",
       " 370: 'perisheth',\n",
       " 371: 'greek',\n",
       " 372: 'whoel',\n",
       " 373: 'hopeless',\n",
       " 374: '-',\n",
       " 375: 'let',\n",
       " 376: 'ruin',\n",
       " 377: 'him',\n",
       " 378: 'king',\n",
       " 379: 'spanish',\n",
       " 380: 'must',\n",
       " 381: 'had',\n",
       " 382: '--',\n",
       " 383: 'octher',\n",
       " 384: 'great',\n",
       " 385: 'bluntly',\n",
       " 386: 'goes',\n",
       " 387: 'commonwealth',\n",
       " 388: 'sebond',\n",
       " 389: 'henry',\n",
       " 390: 'mortality',\n",
       " 391: 'since',\n",
       " 392: 'up',\n",
       " 393: 'indian',\n",
       " 394: 'refugees',\n",
       " 395: 'life',\n",
       " 396: 'also',\n",
       " 397: 'anglo',\n",
       " 398: 'vaulted',\n",
       " 399: 'eye',\n",
       " 400: 'affording',\n",
       " 401: 'icelandic',\n",
       " 402: 'alfred',\n",
       " 403: 'certain',\n",
       " 404: 'beast',\n",
       " 405: 'battle',\n",
       " 406: 'fifty',\n",
       " 407: 'immense',\n",
       " 408: 'cometh',\n",
       " 409: 'sea',\n",
       " 410: 'stone',\n",
       " 411: 'bred',\n",
       " 412: 'would',\n",
       " 413: '[',\n",
       " 414: 'whales',\n",
       " 415: 'prophet',\n",
       " 416: 'we',\n",
       " 417: 'grammars',\n",
       " 418: 'fishes',\n",
       " 419: 'spermacetti',\n",
       " 420: 'supplied',\n",
       " 421: 'book',\n",
       " 422: 'mildly',\n",
       " 423: 'dut',\n",
       " 424: 'seven',\n",
       " 425: 'generations',\n",
       " 426: 'loved',\n",
       " 427: 'apology',\n",
       " 428: 'open',\n",
       " 429: 'swallow',\n",
       " 430: 'breast',\n",
       " 431: 'beating',\n",
       " 432: 'soever',\n",
       " 433: 'clear',\n",
       " 434: 'their',\n",
       " 435: 'random',\n",
       " 436: '890',\n",
       " 437: 'breedeth',\n",
       " 438: 'leviathan',\n",
       " 439: 'appeared',\n",
       " 440: 'view',\n",
       " 441: 'deliver',\n",
       " 442: 'anyways',\n",
       " 443: 'seen',\n",
       " 444: 'entertaining',\n",
       " 445: 'described',\n",
       " 446: 'narrative',\n",
       " 447: 'patient',\n",
       " 448: 'say',\n",
       " 449: 'within',\n",
       " 450: 'what',\n",
       " 451: 'please',\n",
       " 452: 'hie',\n",
       " 453: 'said',\n",
       " 454: 'sallow',\n",
       " 455: 'justly',\n",
       " 456: 'crooked',\n",
       " 457: 'foam',\n",
       " 458: 'grub',\n",
       " 459: 'after',\n",
       " 460: 'killed',\n",
       " 461: 'yards',\n",
       " 462: 'therefore',\n",
       " 463: 'insomuch',\n",
       " 464: 'dictionary',\n",
       " 465: 'nescio',\n",
       " 466: 'dust',\n",
       " 467: 'too',\n",
       " 468: 'peaceful',\n",
       " 469: 'annals',\n",
       " 470: 'authentic',\n",
       " 471: 'william',\n",
       " 472: 'true',\n",
       " 473: 'trouble',\n",
       " 474: 'every',\n",
       " 475: 'cartloads',\n",
       " 476: 'til',\n",
       " 477: 'stalls',\n",
       " 478: 'devilish',\n",
       " 479: 'd',\n",
       " 480: 'coming',\n",
       " 481: 'inward',\n",
       " 482: 'were',\n",
       " 483: 'e',\n",
       " 484: 'sherry',\n",
       " 485: 'thro',\n",
       " 486: 'sperma',\n",
       " 487: 'teach',\n",
       " 488: 'dusting',\n",
       " 489: 'retires',\n",
       " 490: 'worker',\n",
       " 491: 'ibid',\n",
       " 492: 'old',\n",
       " 493: 'sit',\n",
       " 494: 'when',\n",
       " 495: 'rosy',\n",
       " 496: 'fat',\n",
       " 497: 'pale',\n",
       " 498: 'seas',\n",
       " 499: 'promiscuously',\n",
       " 500: 'could',\n",
       " 501: 'melville',\n",
       " 502: 'street',\n",
       " 503: 'heart',\n",
       " 504: 'catching',\n",
       " 505: 'many',\n",
       " 506: 'fegee',\n",
       " 507: 'threadbare',\n",
       " 508: 'appears',\n",
       " 509: 'picking',\n",
       " 510: 'exceeding',\n",
       " 511: 'fish',\n",
       " 512: 'noble',\n",
       " 513: 'reminded',\n",
       " 514: 'leaving',\n",
       " 515: 'spencer',\n",
       " 516: 't',\n",
       " 517: 'morals',\n",
       " 518: 'them',\n",
       " 519: 'wallen',\n",
       " 520: 'play',\n",
       " 521: 'shore',\n",
       " 522: 'threatens',\n",
       " 523: 'biggest',\n",
       " 524: 'cetus',\n",
       " 525: 'gulp',\n",
       " 526: 'nothing',\n",
       " 527: 'lucian',\n",
       " 528: 'saxon',\n",
       " 529: 'who',\n",
       " 530: 'how',\n",
       " 531: 'motion',\n",
       " 532: 'a',\n",
       " 533: 'profane',\n",
       " 534: 'full',\n",
       " 535: 'moses',\n",
       " 536: 'fare',\n",
       " 537: 'mote',\n",
       " 538: 'foul',\n",
       " 539: 'sacred',\n",
       " 540: 'bodies',\n",
       " 541: 'in',\n",
       " 542: 'even',\n",
       " 543: 'this',\n",
       " 544: 'most',\n",
       " 545: ')',\n",
       " 546: 'our',\n",
       " 547: 'not',\n",
       " 548: 'for',\n",
       " 549: 'thee',\n",
       " 550: 'dinting',\n",
       " 551: 'take',\n",
       " 552: 'he',\n",
       " 553: 'acres',\n",
       " 554: 'dragon',\n",
       " 555: 'stowe',\n",
       " 556: 'moby',\n",
       " 557: 'before',\n",
       " 558: 'nick',\n",
       " 559: 'sung',\n",
       " 560: 'lost',\n",
       " 561: 'ger',\n",
       " 562: 'as',\n",
       " 563: 'sleeps',\n",
       " 564: 'lowly',\n",
       " 565: 'worm',\n",
       " 566: 'pan',\n",
       " 567: 'modern',\n",
       " 568: 'deep',\n",
       " 569: 'rolling',\n",
       " 570: 'find',\n",
       " 571: 'pains',\n",
       " 572: 'eight',\n",
       " 573: 'ships',\n",
       " 574: 'named',\n",
       " 575: 'embellished',\n",
       " 576: 'dick',\n",
       " 577: 'glasses',\n",
       " 578: 'to',\n",
       " 579: 'days',\n",
       " 580: 'about',\n",
       " 581: 'secure',\n",
       " 582: 'thirty'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](training_data.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 3\n",
    "windows = flatten([list(nltk.ngrams(['<DUMMY>'] * WINDOW_SIZE + c + ['<DUMMY>'] * WINDOW_SIZE, WINDOW_SIZE * 2 + 1)) for c in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<DUMMY>', '<DUMMY>', '<DUMMY>', '[', 'moby', 'dick', 'by'),\n",
       " ('<DUMMY>', '<DUMMY>', '[', 'moby', 'dick', 'by', 'herman'),\n",
       " ('<DUMMY>', '[', 'moby', 'dick', 'by', 'herman', 'melville'),\n",
       " ('[', 'moby', 'dick', 'by', 'herman', 'melville', '1851')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a n-grams model\n",
    "Training data will be :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[', 'moby'), ('[', 'dick'), ('[', 'by'), ('moby', '['), ('moby', 'dick'), ('moby', 'by')]\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "\n",
    "for window in windows:\n",
    "    for i in range(WINDOW_SIZE * 2 + 1):\n",
    "        if i == WINDOW_SIZE or window[i] == '<DUMMY>': \n",
    "            continue\n",
    "        train_data.append((window[WINDOW_SIZE], window[i]))\n",
    "\n",
    "print(train_data[:WINDOW_SIZE * 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_p = []\n",
    "y_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[', 'moby')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tr in train_data:\n",
    "    X_p.append(prepare_word(tr[0], word2index).view(1, -1))\n",
    "    y_p.append(prepare_word(tr[1], word2index).view(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[413]]),\n",
       " tensor([[413]]),\n",
       " tensor([[413]]),\n",
       " tensor([[556]]),\n",
       " tensor([[556]]),\n",
       " tensor([[556]]),\n",
       " tensor([[556]]),\n",
       " tensor([[576]]),\n",
       " tensor([[576]]),\n",
       " tensor([[576]]),\n",
       " tensor([[576]]),\n",
       " tensor([[576]]),\n",
       " tensor([[290]]),\n",
       " tensor([[290]]),\n",
       " tensor([[290]]),\n",
       " tensor([[290]]),\n",
       " tensor([[290]]),\n",
       " tensor([[290]]),\n",
       " tensor([[50]]),\n",
       " tensor([[50]])]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[556]]),\n",
       " tensor([[576]]),\n",
       " tensor([[290]]),\n",
       " tensor([[413]]),\n",
       " tensor([[576]]),\n",
       " tensor([[290]]),\n",
       " tensor([[50]]),\n",
       " tensor([[413]]),\n",
       " tensor([[556]]),\n",
       " tensor([[290]]),\n",
       " tensor([[50]]),\n",
       " tensor([[501]]),\n",
       " tensor([[413]]),\n",
       " tensor([[556]]),\n",
       " tensor([[576]]),\n",
       " tensor([[50]]),\n",
       " tensor([[501]]),\n",
       " tensor([[58]]),\n",
       " tensor([[556]]),\n",
       " tensor([[576]])]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = list(zip(X_p, y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, projection_dim):\n",
    "        super(Skipgram,self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, projection_dim)\n",
    "        self.embedding_u = nn.Embedding(vocab_size, projection_dim)\n",
    "\n",
    "        self.embedding_v.weight.data.uniform_(-1, 1) # init\n",
    "        self.embedding_u.weight.data.uniform_(0, 0) # init\n",
    "        #self.out = nn.Linear(projection_dim,vocab_size)\n",
    "    def forward(self, center_words,target_words, outer_words):\n",
    "        center_embeds = self.embedding_v(center_words) # B x 1 x D\n",
    "        target_embeds = self.embedding_u(target_words) # B x 1 x D\n",
    "        outer_embeds = self.embedding_u(outer_words) # B x V x D\n",
    "        \n",
    "        # batchwise matrix multiplication\n",
    "        scores = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2) # Bx1xD * BxDx1 => Bx1\n",
    "        norm_scores = outer_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2) # BxVxD * BxDx1 => BxV\n",
    "        \n",
    "        nll = -torch.mean(torch.log(torch.exp(scores)/torch.sum(torch.exp(norm_scores), 1).unsqueeze(1))) # log-softmax\n",
    "        \n",
    "        return nll # negative log likelihood\n",
    "    \n",
    "    def prediction(self, inputs):\n",
    "        embeds = self.embedding_v(inputs)\n",
    "        \n",
    "        return embeds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 30\n",
    "BATCH_SIZE = 256\n",
    "EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "model = Skipgram(len(word2index), EMBEDDING_SIZE)\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, mean_loss : 6.17\n",
      "Epoch : 10, mean_loss : 4.37\n",
      "Epoch : 20, mean_loss : 3.48\n",
      "Epoch : 30, mean_loss : 3.31\n",
      "Epoch : 40, mean_loss : 3.26\n",
      "Epoch : 50, mean_loss : 3.24\n",
      "Epoch : 60, mean_loss : 3.23\n",
      "Epoch : 70, mean_loss : 3.21\n",
      "Epoch : 80, mean_loss : 3.21\n",
      "Epoch : 90, mean_loss : 3.20\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for i, batch in enumerate(getBatch(BATCH_SIZE, train_data)):\n",
    "        \n",
    "        inputs, targets = zip(*batch)\n",
    "        \n",
    "        inputs = torch.cat(inputs) # B x 1\n",
    "        targets = torch.cat(targets) # B x 1\n",
    "        vocabs = prepare_sequence(list(vocab), word2index).expand(inputs.size(0), len(vocab))  # B x V\n",
    "        model.zero_grad()\n",
    "        \n",
    "        \n",
    "        #negative log likelihood\n",
    "        loss = model(inputs, targets, vocabs)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "        losses.append(loss.data.tolist())\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch : %d, mean_loss : %.02f\" % (epoch,np.mean(losses)))\n",
    "        losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   2,   3,  ..., 581, 582,   0],\n",
       "        [  1,   2,   3,  ..., 581, 582,   0],\n",
       "        [  1,   2,   3,  ..., 581, 582,   0],\n",
       "        ...,\n",
       "        [  1,   2,   3,  ..., 581, 582,   0],\n",
       "        [  1,   2,   3,  ..., 581, 582,   0],\n",
       "        [  1,   2,   3,  ..., 581, 582,   0]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_similarity(target, vocab):\n",
    "    target_V = model.prediction(prepare_word(target, word2index))\n",
    "    similarities = []\n",
    "    for i in range(len(vocab)):\n",
    "        if vocab[i] == target: continue\n",
    "        vector = model.prediction(prepare_word(list(vocab)[i], word2index))\n",
    "        cosine_sim = F.cosine_similarity(target_V, vector).data.tolist()[0] \n",
    "        similarities.append([vocab[i], cosine_sim])\n",
    "    return sorted(similarities, key=lambda x: x[1], reverse=True)[:10] # sort by similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'any'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = random.choice(list(vocab))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['book', 0.7919671535491943],\n",
       " ['find', 0.660162091255188],\n",
       " ['picking', 0.5818719863891602],\n",
       " ['whatsoever', 0.5688313841819763],\n",
       " ['anyways', 0.5544962882995605],\n",
       " ['vast', 0.5483270287513733],\n",
       " ['nothing', 0.5259244441986084],\n",
       " ['gulf', 0.5102213621139526],\n",
       " ['nescio', 0.5036137700080872],\n",
       " ['own', 0.4889150857925415]]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity(test, vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
